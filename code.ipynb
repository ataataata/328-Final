{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from scipy.signal import butter, filtfilt, find_peaks\n",
    "from sklearn.tree import DecisionTreeClassifier,export_graphviz\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding helpers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_magnitude(data):\n",
    "\n",
    "    # Calculate magnitude\n",
    "    data['accel_mag'] = np.sqrt(data['x']**2 + data['y']**2 + data['z']**2) # absolute accel magnitude\n",
    "    data['accel_mag'] = data['accel_mag'] - data['accel_mag'].mean() # detrend: \"remove gravity\"\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(data,sampling_rate):\n",
    "    from scipy.signal import butter, filtfilt, find_peaks\n",
    "\n",
    "    # Low pass filter\n",
    "    cutoff = 5 # Hz\n",
    "    order = 2\n",
    "    b, a = butter(order, cutoff/(sampling_rate/2), btype='lowpass')\n",
    "    data['filtered_accel_mag'] = filtfilt(b, a, data['accel_mag'])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(window):\n",
    "    features = {}\n",
    "    features['avg'] = window['filtered_accel_mag'].mean()\n",
    "    features['max'] = window['filtered_accel_mag'].quantile(1)\n",
    "    features['med'] = window['filtered_accel_mag'].quantile(0.5)\n",
    "    features['min'] = window['filtered_accel_mag'].quantile(0)\n",
    "    features['q25'] = window['filtered_accel_mag'].quantile(0.25)\n",
    "    features['q75'] = window['filtered_accel_mag'].quantile(0.75)\n",
    "    features['std'] = window['filtered_accel_mag'].std()\n",
    "    df = pd.DataFrame()\n",
    "    df = df._append(features,ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decision_tree(frames):\n",
    "    # Extract feature columns\n",
    "    X = frames[['avg', 'max', 'med', 'min', 'q25', 'q75', 'std']]\n",
    "\n",
    "    # Extract target column\n",
    "    y = frames['activity']\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Create model\n",
    "    dt_model = DecisionTreeClassifier(criterion='entropy',max_depth=5).fit(X_train, y_train)\n",
    "    dt_pred = dt_model.predict(X_test)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    acc = dt_model.score(X_test, y_test)\n",
    "    dt_cm = confusion_matrix(y_test, dt_pred, labels=dt_model.classes_)\n",
    "    print(classification_report(y_test, dt_pred))\n",
    "    print(\"Accuracy on test set:\", acc)\n",
    "\n",
    "    return dt_model,dt_cm,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calulating the orientation for sleep tracking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_orientation(data):\n",
    "    data['pitch'] = np.arctan2(data['y'], np.sqrt(data['x']**2 + data['z']**2))\n",
    "    data['roll'] = np.arctan2(-data['x'], data['z'])    \n",
    "    data['pitch'] = np.degrees(data['pitch'])\n",
    "    data['roll'] = np.degrees(data['roll'])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding extra feauters for sleep position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_position_features(window):\n",
    "    features = {}\n",
    "    \n",
    "    base_features = add_features(window)\n",
    "    \n",
    "    features['pitch_mean'] = window['pitch'].mean()\n",
    "    features['pitch_std'] = window['pitch'].std()\n",
    "    features['roll_mean'] = window['roll'].mean()\n",
    "    features['roll_std'] = window['roll'].std()\n",
    "    \n",
    "    features['stability'] = window['filtered_accel_mag'].std() / window['filtered_accel_mag'].mean()\n",
    "    features['movement_intensity'] = np.sum(np.abs(np.diff(window['filtered_accel_mag'])))\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df = df._append({**base_features.iloc[0], **features}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_position_features(data, window_sec, sample_rate, position):\n",
    "    data['timestamp'] = pd.to_datetime(data.index, unit='s')\n",
    "    data.set_index('timestamp', inplace=True)\n",
    "    \n",
    "    data = calc_orientation(data)\n",
    "    \n",
    "    window_size = f'{window_sec}s'\n",
    "    \n",
    "    resampled_data = data.resample(window_size)\n",
    "    \n",
    "    features_df = pd.DataFrame()\n",
    "    \n",
    "    for timestamp, window in resampled_data:\n",
    "        if not window.empty:\n",
    "            features = add_position_features(window)\n",
    "            \n",
    "            features['position'] = position\n",
    "            \n",
    "            features_df = pd.concat([features_df, features], ignore_index=True)\n",
    "    \n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_position_classifier(frames):\n",
    "    features = ['avg', 'max', 'med', 'min', 'q25', 'q75', 'std',\n",
    "                'pitch_mean', 'pitch_std', 'roll_mean', 'roll_std',\n",
    "                'stability', 'movement_intensity']\n",
    "    \n",
    "    X = frames[features]\n",
    "    y = frames['position']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    dt_model = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        max_depth=6,  \n",
    "        min_samples_leaf=5  \n",
    "    ).fit(X_train, y_train)\n",
    "    \n",
    "    dt_pred = dt_model.predict(X_test)\n",
    "\n",
    "    acc = dt_model.score(X_test, y_test)\n",
    "    dt_cm = confusion_matrix(y_test, dt_pred, labels=dt_model.classes_)\n",
    "    print(classification_report(y_test, dt_pred))\n",
    "    print(\"Accuracy on test set:\", acc)\n",
    "\n",
    "    return dt_model, dt_cm, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Burdan sonrasi komple GPT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_merge_data(accel_file, gyro_file, sample_rate):\n",
    "    # Load accelerometer data\n",
    "    accel_data = pd.read_csv(accel_file)\n",
    "    gyro_data = pd.read_csv(gyro_file)\n",
    "\n",
    "    # Assuming columns are: time, x, y, z\n",
    "    # Rename for clarity: ax, ay, az for accel; gx, gy, gz for gyro\n",
    "    # Convert time to datetime if needed\n",
    "    accel_data['timestamp'] = pd.to_datetime(accel_data['time'])\n",
    "    gyro_data['timestamp'] = pd.to_datetime(gyro_data['time'])\n",
    "\n",
    "    accel_data.set_index('timestamp', inplace=True)\n",
    "    gyro_data.set_index('timestamp', inplace=True)\n",
    "\n",
    "    # Resample both to ensure same frequency and align times\n",
    "    accel_data = accel_data.resample(f'{1/sample_rate}S').mean().interpolate()\n",
    "    gyro_data = gyro_data.resample(f'{1/sample_rate}S').mean().interpolate()\n",
    "\n",
    "    # Merge on nearest timestamps\n",
    "    merged = pd.merge_asof(accel_data.sort_index(), gyro_data.sort_index(),\n",
    "                           left_index=True, right_index=True, direction='nearest',\n",
    "                           suffixes=('_accel','_gyro'))\n",
    "\n",
    "    # Rename columns to standard names\n",
    "    merged.rename(columns={\n",
    "        'x_accel': 'ax', 'y_accel': 'ay', 'z_accel': 'az',\n",
    "        'x_gyro': 'gx', 'y_gyro': 'gy', 'z_gyro': 'gz'\n",
    "    }, inplace=True)\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_combined_features(data, window_sec, sample_rate, position):\n",
    "    # Compute accel magnitude and remove noise\n",
    "    data = calc_magnitude(data)\n",
    "    data = remove_noise(data, sample_rate)\n",
    "\n",
    "    # Compute orientation from accelerometer\n",
    "    # The calc_orientation expects 'x','y','z' columns, so map ax,ay,az\n",
    "    data['x'] = data['ax']\n",
    "    data['y'] = data['ay']\n",
    "    data['z'] = data['az']\n",
    "    data = calc_orientation(data)\n",
    "\n",
    "    # Now we have accel_mag, filtered_accel_mag, pitch, roll\n",
    "    # Also have gyro data: gx, gy, gz\n",
    "\n",
    "    # Add gyro magnitude if needed\n",
    "    data['gyro_mag'] = np.sqrt(data['gx']**2 + data['gy']**2 + data['gz']**2)\n",
    "\n",
    "    # Resample into windows\n",
    "    data['timestamp'] = data.index\n",
    "    data.set_index('timestamp', inplace=True)\n",
    "\n",
    "    window_size = f'{window_sec}s'\n",
    "    resampled_data = data.resample(window_size)\n",
    "\n",
    "    features_df = pd.DataFrame()\n",
    "\n",
    "    for timestamp, window in resampled_data:\n",
    "        if not window.empty:\n",
    "            # Basic accel features\n",
    "            base_features = add_features(window)  # avg, max, med, min, q25, q75, std (from filtered_accel_mag)\n",
    "\n",
    "            # Orientation features\n",
    "            orientation_feats = {\n",
    "                'pitch_mean': window['pitch'].mean(),\n",
    "                'pitch_std': window['pitch'].std(),\n",
    "                'roll_mean': window['roll'].mean(),\n",
    "                'roll_std': window['roll'].std()\n",
    "            }\n",
    "\n",
    "            # Stability and movement intensity\n",
    "            # stability = std/mean of filtered_accel_mag\n",
    "            mean_val = window['filtered_accel_mag'].mean() if window['filtered_accel_mag'].mean() != 0 else 1e-9\n",
    "            stability = window['filtered_accel_mag'].std() / mean_val\n",
    "            movement_intensity = np.sum(np.abs(np.diff(window['filtered_accel_mag'])))\n",
    "\n",
    "            extra_feats = {\n",
    "                'stability': stability,\n",
    "                'movement_intensity': movement_intensity\n",
    "            }\n",
    "\n",
    "            combined_features = {**base_features.iloc[0], **orientation_feats, **extra_feats}\n",
    "            combined_features['position'] = position\n",
    "\n",
    "            features_df = pd.concat([features_df, pd.DataFrame([combined_features])], ignore_index=True)\n",
    "\n",
    "    return features_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_combined_data(accel_root, gyro_root, output_filename=\"combined_sleep_data.csv\", window_sec=5, sample_rate=100):\n",
    "    all_data = pd.DataFrame()\n",
    "\n",
    "    for position in ['back', 'side', 'stomach']:\n",
    "        accel_files = glob.glob(os.path.join(accel_root, position, '*.csv'))\n",
    "\n",
    "        for accel_file in accel_files:\n",
    "            filename = os.path.basename(accel_file)\n",
    "            gyro_file = os.path.join(gyro_root, position, filename)\n",
    "\n",
    "            if not os.path.exists(gyro_file):\n",
    "                print(f\"No matching gyro file for {accel_file}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            merged_data = load_and_merge_data(accel_file, gyro_file, sample_rate)\n",
    "\n",
    "            features_df = extract_combined_features(merged_data, window_sec, sample_rate, position)\n",
    "            all_data = pd.concat([all_data, features_df], ignore_index=True)\n",
    "\n",
    "    all_data.to_csv(output_filename, index=False)\n",
    "    return all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_position_classifier(frames):\n",
    "    # Ensure the needed features are present\n",
    "    features = [\n",
    "        'avg', 'max', 'med', 'min', 'q25', 'q75', 'std',\n",
    "        'pitch_mean', 'pitch_std', 'roll_mean', 'roll_std',\n",
    "        'stability', 'movement_intensity'\n",
    "    ]\n",
    "\n",
    "    X = frames[features]\n",
    "    y = frames['position']\n",
    "\n",
    "    # Stratify to maintain position distribution\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    dt_model = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        max_depth=6,\n",
    "        min_samples_leaf=5\n",
    "    ).fit(X_train, y_train)\n",
    "\n",
    "    dt_pred = dt_model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, dt_pred)\n",
    "    print(classification_report(y_test, dt_pred))\n",
    "    print(\"Accuracy on test set:\", acc)\n",
    "\n",
    "    dt_cm = confusion_matrix(y_test, dt_pred, labels=dt_model.classes_)\n",
    "\n",
    "    return dt_model, dt_cm, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['avg', 'max', 'med', 'min', 'q25', 'q75', 'std', 'pitch_mean',\\n       'pitch_std', 'roll_mean', 'roll_std', 'stability',\\n       'movement_intensity'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m all_data \u001b[38;5;241m=\u001b[39m process_combined_data(accel_root, gyro_root, output_file, window_sec\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, sample_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Train the classifier\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m dt_model, dt_cm, acc \u001b[38;5;241m=\u001b[39m train_position_classifier(all_data)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Print confusion matrix\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfusion Matrix:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, dt_cm)\n",
      "Cell \u001b[0;32mIn[20], line 9\u001b[0m, in \u001b[0;36mtrain_position_classifier\u001b[0;34m(frames)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_position_classifier\u001b[39m(frames):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Ensure the needed features are present\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     features \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq25\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq75\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpitch_mean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpitch_std\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroll_mean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroll_std\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstability\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovement_intensity\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m     ]\n\u001b[0;32m----> 9\u001b[0m     X \u001b[38;5;241m=\u001b[39m frames[features]\n\u001b[1;32m     10\u001b[0m     y \u001b[38;5;241m=\u001b[39m frames[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Stratify to maintain position distribution\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['avg', 'max', 'med', 'min', 'q25', 'q75', 'std', 'pitch_mean',\\n       'pitch_std', 'roll_mean', 'roll_std', 'stability',\\n       'movement_intensity'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "accel_root = './data/accelerometer'\n",
    "gyro_root = './data/gyroscope'\n",
    "output_file = \"combined_sleep_data.csv\"\n",
    "\n",
    "# Process data and extract features\n",
    "all_data = process_combined_data(accel_root, gyro_root, output_file, window_sec=5, sample_rate=100)\n",
    "\n",
    "# Train the classifier\n",
    "dt_model, dt_cm, acc = train_position_classifier(all_data)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", dt_cm)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "position_labels = all_data['position'].unique()\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(dt_cm, annot=True, fmt='d', cmap='Blues', xticklabels=position_labels, yticklabels=position_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix for Sleep Position Classification')\n",
    "plt.show()\n",
    "\n",
    "# Visualize feature importance\n",
    "features = [\n",
    "    'avg', 'max', 'med', 'min', 'q25', 'q75', 'std',\n",
    "    'pitch_mean', 'pitch_std', 'roll_mean', 'roll_std',\n",
    "    'stability', 'movement_intensity'\n",
    "]\n",
    "importances = dt_model.feature_importances_\n",
    "fi_df = pd.DataFrame({'Feature': features, 'Importance': importances}).sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x='Importance', y='Feature', data=fi_df)\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
