{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from scipy.signal import butter, filtfilt, find_peaks\n",
    "from sklearn.tree import DecisionTreeClassifier,export_graphviz\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding helpers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_magnitude(data):\n",
    "\n",
    "    # Calculate magnitude\n",
    "    data['accel_mag'] = np.sqrt(data['x']**2 + data['y']**2 + data['z']**2) # absolute accel magnitude\n",
    "    data['accel_mag'] = data['accel_mag'] - data['accel_mag'].mean() # detrend: \"remove gravity\"\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(data,sampling_rate):\n",
    "    from scipy.signal import butter, filtfilt, find_peaks\n",
    "\n",
    "    # Low pass filter\n",
    "    cutoff = 5 # Hz\n",
    "    order = 2\n",
    "    b, a = butter(order, cutoff/(sampling_rate/2), btype='lowpass')\n",
    "    data['filtered_accel_mag'] = filtfilt(b, a, data['accel_mag'])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(window):\n",
    "    features = {}\n",
    "    features['avg'] = window['filtered_accel_mag'].mean()\n",
    "    features['max'] = window['filtered_accel_mag'].quantile(1)\n",
    "    features['med'] = window['filtered_accel_mag'].quantile(0.5)\n",
    "    features['min'] = window['filtered_accel_mag'].quantile(0)\n",
    "    features['q25'] = window['filtered_accel_mag'].quantile(0.25)\n",
    "    features['q75'] = window['filtered_accel_mag'].quantile(0.75)\n",
    "    features['std'] = window['filtered_accel_mag'].std()\n",
    "    df = pd.DataFrame()\n",
    "    df = df._append(features,ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decision_tree(frames):\n",
    "    # Extract feature columns\n",
    "    X = frames[['avg', 'max', 'med', 'min', 'q25', 'q75', 'std']]\n",
    "\n",
    "    # Extract target column\n",
    "    y = frames['activity']\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Create model\n",
    "    dt_model = DecisionTreeClassifier(criterion='entropy',max_depth=5).fit(X_train, y_train)\n",
    "    dt_pred = dt_model.predict(X_test)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    acc = dt_model.score(X_test, y_test)\n",
    "    dt_cm = confusion_matrix(y_test, dt_pred, labels=dt_model.classes_)\n",
    "    print(classification_report(y_test, dt_pred))\n",
    "    print(\"Accuracy on test set:\", acc)\n",
    "\n",
    "    return dt_model,dt_cm,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gyro_features(data):\n",
    "    data['gyro_mag'] = np.sqrt(data['gx']**2 + data['gy']**2 + data['gz']**2)\n",
    "    data['gyro_mag'] = data['gyro_mag'] - data['gyro_mag'].mean()  # detrend\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calulating the orientation for sleep tracking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_orientation(data):\n",
    "    data['pitch'] = np.arctan2(data['y'], np.sqrt(data['x']**2 + data['z']**2))\n",
    "    data['roll'] = np.arctan2(-data['x'], data['z'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding extra feauters for sleep position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_position_features(window):\n",
    "    features = {}\n",
    "    \n",
    "    base_features = add_features(window)\n",
    "    \n",
    "    features['pitch_mean'] = window['pitch'].mean()\n",
    "    features['pitch_std'] = window['pitch'].std()\n",
    "    features['roll_mean'] = window['roll'].mean()\n",
    "    features['roll_std'] = window['roll'].std()\n",
    "    \n",
    "    features['stability'] = window['filtered_accel_mag'].std() / window['filtered_accel_mag'].mean()\n",
    "    features['movement_intensity'] = np.sum(np.abs(np.diff(window['filtered_accel_mag'])))\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df = df._append({**base_features.iloc[0], **features}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_position_features(data, window_sec, sample_rate, position):\n",
    "    data['timestamp'] = pd.to_datetime(data.index, unit='s')\n",
    "    data.set_index('timestamp', inplace=True)\n",
    "    \n",
    "    data = calc_orientation(data)\n",
    "    \n",
    "    window_size = f'{window_sec}s'\n",
    "    \n",
    "    resampled_data = data.resample(window_size)\n",
    "    \n",
    "    features_df = pd.DataFrame()\n",
    "    \n",
    "    for timestamp, window in resampled_data:\n",
    "        if not window.empty:\n",
    "            features = add_position_features(window)\n",
    "            \n",
    "            features['position'] = position\n",
    "            \n",
    "            features_df = pd.concat([features_df, features], ignore_index=True)\n",
    "    \n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_position_classifier(frames):\n",
    "    features = ['avg', 'max', 'med', 'min', 'q25', 'q75', 'std',\n",
    "                'pitch_mean', 'pitch_std', 'roll_mean', 'roll_std',\n",
    "                'stability', 'movement_intensity']\n",
    "    \n",
    "    X = frames[features]\n",
    "    y = frames['position']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    dt_model = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        max_depth=6,  \n",
    "        min_samples_leaf=5  \n",
    "    ).fit(X_train, y_train)\n",
    "    \n",
    "    dt_pred = dt_model.predict(X_test)\n",
    "\n",
    "    acc = dt_model.score(X_test, y_test)\n",
    "    dt_cm = confusion_matrix(y_test, dt_pred, labels=dt_model.classes_)\n",
    "    print(classification_report(y_test, dt_pred))\n",
    "    print(\"Accuracy on test set:\", acc)\n",
    "\n",
    "    return dt_model, dt_cm, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sleep_data(root, output_filename=\"sleep_data.csv\"):\n",
    "    all_data = pd.DataFrame()\n",
    "    \n",
    "    csv_files = glob.glob(os.path.join(root, '**', '*.csv'), recursive=True)\n",
    "    \n",
    "    for file in csv_files:\n",
    "        position = os.path.basename(os.path.dirname(file))\n",
    "        \n",
    "        data = pd.read_csv(file)\n",
    "        \n",
    "        data = calc_magnitude(data)\n",
    "        data = calc_orientation(data)  \n",
    "        data = remove_noise(data, 100)  \n",
    "        \n",
    "        features_df = extract_position_features(data, 5, 100, position)\n",
    "        \n",
    "        all_data = pd.concat([all_data, features_df], ignore_index=True)\n",
    "    \n",
    "    all_data.to_csv(output_filename, index=False)\n",
    "    return all_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
